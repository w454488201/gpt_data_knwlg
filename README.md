# gpt_data_knwlg
第一个尝试上传git的代码。结合gpt api用来探索gpt+知识库有没有比较轻量级可商用的小模型，用于中小企业各种场景里


首先保证你有一个pandas可以打开任意格式表格型材料。把材料做成title，content这种形式。注意整体格式。
其次你需要保证有一个海外服务器，因为我实际测试除了第一步，其他的都无法在国内完成。api连不上的。

本地运行STEP1OFFLINE即可。
结果会生成一个新的csv，上面有token计算和合并结果
#### 不介意，可以直接上传中文，也不是不行，就是可能不准确。建议先通过translator运行，会创建新的两行，把所有内容改英文。然后再放进去。百度个人开发者每月好像有一万字的免费额度吧，个人够用了。如果企业客户有100万字。
#### 下面的全部过程都是用这个思路的！
然后接下来所有过程都需要放到你的海外服务器上进行
运行TOFAISSSQL，向量化合并后的title和content。注意我这里合并的是我##翻译后##的所有的数据进行储存。

然后数据全部配置好之后，启动STEP2APP,即可。

#### 目前测试下来，主要是速度不怎么快。3.5表现还是很好的。我这里没用finetuning，用完微调应该会更好。
#### 当前最大的缺陷是3.5会编排一部分不存在的东西。不微调遇到没提到的问题，会说假话。在这个场景里，实际上是有问题的，因为说错话比不说话问题大多了。

#### 实际上我期待的是本地化的，小模型。因为其实仅涉及到信息交换，不需要ai有太高的智能，太高反而给他自我发挥的空间了。我就是要让你做机械的工作的。所以我觉得以后小模型和大模型是会共存的。大模型来做医疗教育等等精确且复杂的东西。小模型本地化更安全，商业场景也更多

这是我第一次上传git，代码工作中很多问题是请教gpt4才解决的。比如redis之类的我实际上不是很理解，以前没加，说是能更稳定我才加进去的。

有觉得哪里不对的或者不好的，请留言。
