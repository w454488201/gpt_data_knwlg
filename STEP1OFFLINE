###版本5.11 这是线下本地可以做的唯一一步，这一步不需要外网即可。主要用途是线下快速的合并title和content，并且计算总共的token
###


import pandas as pd
import tiktoken
import openai
from openai.embeddings_utils import get_embedding

openai.api_key = "YOUR_OPENAI_KEY"


embedding_model = "text-embedding-ada-002"
embedding_encoding = "cl100k_base"  # this the encoding for text-embedding-ada-002
max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191

input_datapath = "YOUR/DATA/PATH"  # to save space, we provide a pre-filtered dataset
df = pd.read_csv(input_datapath)

df["combined"] = (
    "title: " + df.title.str.strip() + "; content: " + df.content.str.strip()
)
df["eng_combined"] = (
    "eng_title: " + df.eng_title.str.strip() + "; en_content: " + df.en_content.str.strip()
)
df.head(2)
print(df)

# subsample to 1k most recent reviews and remove samples that are too long
top_n = 3000
# df = df.sort_values("Time").tail(top_n * 2)  # first cut to first 2k entries, assuming less than half will be filtered out
# df.drop("Time", axis=1, inplace=True)

encoding = tiktoken.get_encoding(embedding_encoding)

# omit reviews that are too long to embed
df["n_tokens"] = df.combined.astype(str).apply(lambda x: len(encoding.encode(x)))

df = df[df.n_tokens <= max_tokens].tail(top_n)
print(len(df))
print(df)
df.to_csv("YOUR/DATA/PATH")
# df["embedding"] = df.combined.apply(lambda x: get_embedding(x, engine=embedding_model))
# df.to_csv("XXX.CSV")
